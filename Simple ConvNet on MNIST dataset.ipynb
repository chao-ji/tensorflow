{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders for input (batch, 784) and output (batch, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**x_image**: tensor of shape [-1, 28, 28, 1]\n",
    "* -1: Batch size (computed from data)\n",
    "* 28: Height of image\n",
    "* 28: Width of image\n",
    "* 1: Numbers of color channels (MNIST images are black-white, so only one color channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first Conv layer contains 32 filters each with a unique set of learnable values: 5 \\* 5 \\* 1 weights, plus one bias.\n",
    "\n",
    "The total number of parameters is 32 \\* (5 \\* 5 \\* 1 + 1) = 832\n",
    "\n",
    "**W_conv1**: tensor of shape [5, 5, 1, 32]\n",
    "* 5: Height of receptive field\n",
    "* 5: Width of receptive field\n",
    "* 1: Number of input channels\n",
    "* 32: Number of depth slices in the output volume (or number of filters applied on the input volume)\n",
    "\n",
    "**b_conv1**: tensor of shape [32]\n",
    "* 32: The biases of the 32 filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters of the first Conv layer should be:\n",
    "* Input size (**W**): 28\n",
    "* Patch size of filter (**F**): 5\n",
    "* Stride with which filter is applied on input image (**S**): 1\n",
    "* Size of zero-padding (**P**): 2\n",
    "\n",
    "(W - F + 2P) / S + 1 = (28 - 5 + 2 \\* 2) / 1 + 1 = 28, which is the same as the input image size\n",
    "\n",
    "So the first Conv layer will transform an input image of shape (batch, 28, 28, 1) into (batch, 28, 28, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first Pool layer has the following hyperparameters:\n",
    "* Patch size (**F**): 2\n",
    "* Stride (**S**): 2\n",
    "\n",
    "So the first Pool layer will pick the max of the four values for each of the non-overlapping 2-by-2 patch. The (batch, 28, 28, 32) tensor output from the first Conv layer will be transformed into a (batch, 14, 14, 32) tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the second Conv layer contains 64 filters so it will transform input tensor of shape (batch, 14, 14, 32) into (batch, 14, 14, 64) tensor; and the second Pool layer will transform input tensor of shape (batch, 14, 14, 64) into (batch, 7, 7, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output volume from the second Pool layer of shape (batch, 7, 7, 64) will be reshaped into (batch, 7\\*7\\*64)\n",
    "\n",
    "It will be transformed in to tensor of shape (batch, 1024) by 1024 neurons each containing 7\\*7\\*64 weights, that is, (batch, 7\\*7\\*64) dot (7\\*7\\*64, 1024) = (batch, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training a subset of the 1024 neuros will be dropout with a given probability, those that were kept will be scaled to make sure that their expected sum will be approximately the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need a readout layer that transform tensor of shape (batch, 1024) into (batch, 10) ((batch, 1024) dot (1024, 10)), which are interpreted as the confidence scores for the 10 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of learnable parameters (3,274,634) is calculated as follows \n",
    "\n",
    "* First Conv layer: 32 \\* (5 \\* 5 \\* 1 + 1) = 832\n",
    "* Second Conv layer: 64 \\* (5 \\* 5 \\* 32 + 1) = 51,264\n",
    "* Fully connected layer: 7\\*7\\*64 \\* 1024 + 1024 = 3,212,288\n",
    "* Readout layer (fully connected): 1024 \\* 10 + 10 = 10,250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.14\n",
      "step 2000, training accuracy 0.98\n",
      "step 4000, training accuracy 0.98\n",
      "step 6000, training accuracy 0.98\n",
      "step 8000, training accuracy 1\n",
      "step 10000, training accuracy 1\n",
      "step 12000, training accuracy 1\n",
      "step 14000, training accuracy 1\n",
      "step 16000, training accuracy 1\n",
      "step 18000, training accuracy 1\n"
     ]
    }
   ],
   "source": [
    "# labels: true class labels\n",
    "# logits: predicted confidence scores for class labels\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i % 2000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print \"step %d, training accuracy %g\" % (i, train_accuracy)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step = 1000\n",
    "result = []\n",
    "for i in range(0, 10000, 1000):\n",
    "    result.append(accuracy.eval(feed_dict={x: mnist.test.images[i:i+step],\n",
    "                                           y_: mnist.test.labels[i:i+step],\n",
    "                                           keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99100006, 0.98400009, 0.98099995, 0.99100006, 0.99100006, 0.99900007, 0.995, 1.0000001, 0.99800014, 0.99199998]\n",
      "accuracy = 0.9922\n"
     ]
    }
   ],
   "source": [
    "print result\n",
    "print \"accuracy =\", np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
